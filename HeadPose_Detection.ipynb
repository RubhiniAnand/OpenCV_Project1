{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTrq5efx869oRV6rvK8/jj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16SonXLCEhhrg0nr-_oMabWlWRfRdd-R4"},"id":"aF0Fw5tot77S","executionInfo":{"status":"ok","timestamp":1719497633700,"user_tz":-330,"elapsed":133539,"user":{"displayName":"Rubhini Anand","userId":"10825664432299601527"}},"outputId":"fb82c791-8f88-49bf-e5fa-acfb874a010e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import dlib\n","import numpy as np\n","from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load Dlib's pre-trained face detector and shape predictor model\n","detector = dlib.get_frontal_face_detector()\n","predictor_path = '/content/drive/MyDrive/HeadPose/shape_predictor_68_face_landmarks.dat'\n","\n","if not os.path.isfile(predictor_path):\n","    raise FileNotFoundError(f\"Predictor file not found at {predictor_path}\")\n","\n","predictor = dlib.shape_predictor(predictor_path)\n","\n","# Camera matrix and distortion coefficients (assuming no lens distortion)\n","cam_matrix = np.array([[640, 0, 320],\n","                       [0, 640, 240],\n","                       [0, 0, 1]], dtype='double')\n","dist_coeffs = np.zeros((4, 1))\n","\n","# 3D model points of a generic face\n","model_points = np.array([\n","    (0.0, 0.0, 0.0),  # Nose tip\n","    (0.0, -330.0, -65.0),  # Chin\n","    (-225.0, 170.0, -135.0),  # Left eye left corner\n","    (225.0, 170.0, -135.0),  # Right eye right corner\n","    (-150.0, -150.0, -125.0),  # Left Mouth corner\n","    (150.0, -150.0, -125.0)  # Right mouth corner\n","])\n","\n","def get_2d_image_points(shape):\n","    \"\"\" Get 2D image points from the 68 facial landmarks \"\"\"\n","    image_points = np.array([\n","        (shape.part(30).x, shape.part(30).y),  # Nose tip\n","        (shape.part(8).x, shape.part(8).y),  # Chin\n","        (shape.part(36).x, shape.part(36).y),  # Left eye left corner\n","        (shape.part(45).x, shape.part(45).y),  # Right eye right corner\n","        (shape.part(48).x, shape.part(48).y),  # Left Mouth corner\n","        (shape.part(54).x, shape.part(54).y)  # Right mouth corner\n","    ], dtype='double')\n","    return image_points\n","\n","def main(vid):\n","    cap = cv2.VideoCapture(vid)  # Capture video from the provided file\n","    # Define the codec and create VideoWriter object\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    out = cv2.VideoWriter('/content/drive/MyDrive/HeadPose/final_video.mp4', fourcc, 25.0, (640, 360))\n","\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = detector(gray)\n","\n","        for face in faces:\n","            shape = predictor(gray, face)\n","            image_points = get_2d_image_points(shape)\n","\n","            # SolvePnP to estimate head pose\n","            success, rotation_vector, translation_vector = cv2.solvePnP(\n","                model_points, image_points, cam_matrix, dist_coeffs)\n","\n","            # Project the points back to the 2D image plane\n","            (nose_end_point2D, _) = cv2.projectPoints(\n","                np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, cam_matrix, dist_coeffs)\n","\n","            # Draw detected face landmarks\n","            for (x, y) in image_points:\n","                cv2.circle(frame, (int(x), int(y)), 3, (0, 0, 255), -1)\n","\n","            # Draw a line from the nose tip to the projected point to indicate head direction\n","            p1 = (int(image_points[0][0]), int(image_points[0][1]))\n","            p2 = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n","            cv2.line(frame, p1, p2, (255, 0, 0), 2)\n","            direction = \"Head Direction: \"\n","\n","            if p2[0] > p1[0] + 20:\n","                direction += \"Facing Right\"\n","            elif p2[0] < p1[0] - 20:\n","                direction += \"Facing Left\"\n","            else:\n","                direction += \"Facing Forward\"\n","\n","            #cv2.putText(frame, direction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 150, 50), 2, cv2.LINE_AA)\n","            cv2.putText(frame, direction, (face.left(), face.top() - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2, cv2.LINE_AA)\n","\n","        out.write(frame)  # Write the frame to the video file\n","\n","        # If you want to display the frame in Google Colab (optional)\n","        cv2_imshow(frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","if __name__ == '__main__':\n","    video_path = '/content/drive/MyDrive/HeadPose/genderdetection_video.mp4'  # Replace with your video file path\n","    main(video_path)"]}]}